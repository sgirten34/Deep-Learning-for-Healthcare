{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "55c9b7a726ac84c44a2d45e4a591367c",
     "grade": false,
     "grade_id": "cell-e5edec0425de3a50",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# HW2 Embedding\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this homework, you will try some embedding models on text data and visualize those learned embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:51:43.820188Z",
     "start_time": "2022-02-07T05:51:43.812512Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "621bf724f8457115b5fe8a730ce68651",
     "grade": false,
     "grade_id": "cell-4c4fd1b10bb8a9d5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "DATA_PATH = \"../HW2_Embedding-lib/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e1f7afb6dda410c10d2384942e05e50e",
     "grade": false,
     "grade_id": "cell-cb803a823f1d765d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## About Raw Data\n",
    "\n",
    "Navigate to `DATA_PATH`, there is a csv file used for training. The data is originally from the [NFCorpus database](https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:51:43.948914Z",
     "start_time": "2022-02-07T05:51:43.822662Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d6c11676cd46fd3af9caf9d88171fcde",
     "grade": false,
     "grade_id": "cell-7177107106467bac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "!ls {DATA_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d22e62cddd766348a1592c7b9e746205",
     "grade": false,
     "grade_id": "cell-a069bf0ccf3fe69c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The data provided in *corpus.csv* consists of medical articles from [PubMed](https://pubmed.ncbi.nlm.nih.gov)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:51:44.532717Z",
     "start_time": "2022-02-07T05:51:43.951315Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c901d9bd05534dca0a7464b7d620c695",
     "grade": false,
     "grade_id": "cell-6875d3fe31b5dc38",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_dataset(filepath):    \n",
    "    \"\"\" Read the cospus.csv file \"\"\"\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "\n",
    "corpus_df = load_dataset(os.path.join(DATA_PATH, 'corpus.csv'))\n",
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "286d13e56e9009b2c0ef4b276a630f0c",
     "grade": false,
     "grade_id": "cell-f336fcb19e9320b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1 Word2Vec [60 points]\n",
    "\n",
    "In this question, you will perform word2vec on the given NFCorpus dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d6cedfe68e2297f27fca4ce1fee1a814",
     "grade": false,
     "grade_id": "cell-310d771751f41c87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.1 Preprocess the text data [20 points]\n",
    "\n",
    "In order to preprocess the text data, you should:\n",
    "- Remove newline ('\\n')\n",
    "- Remove carriage returns ('\\r')\n",
    "- Remove punctuations\n",
    "- Remove numbers\n",
    "- Convert to lower-case\n",
    "- Split each sentence into a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:51:45.819660Z",
     "start_time": "2022-02-07T05:51:44.534998Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    "# PLEASE USE THE GIVEN FUNCTION NAME, DO NOT CHANGE IT\n",
    "\n",
    "\n",
    "#input\n",
    "# corpus_df: a dataframe returned by `load_dataset`\n",
    "#output\n",
    "# corpus_processed: a list of articles where each article is broke into a list of words \n",
    "def preprocess_dataset(df):    \n",
    "    ''' Preprocess the text data. And return a list of articles. '''\n",
    "    corpus_processed = []\n",
    "    \n",
    "    df.TEXT = df.TEXT.str.replace('\\n', '')  # remove newline\n",
    "    df.TEXT = df.TEXT.str.replace('\\r', '')  # carriage returns\n",
    "    \"\"\"\n",
    "    TODO: 1. remove punctuations;\n",
    "          2. remove numbers.\n",
    "          \n",
    "    HINT: consider using `string.punctuation`, `str.maketrans`, and `str.translate`.\n",
    "    \"\"\"\n",
    "\n",
    "    df.TEXT = df.TEXT.str.translate(str.maketrans('', '', string.punctuation))\n",
    "    df.TEXT = df.TEXT.str.translate(str.maketrans('', '', string.digits))\n",
    "    \n",
    "    df.TEXT = df.TEXT.str.lower()  # convert to lower case\n",
    "    \n",
    "    # tokenize\n",
    "    for note in df.TEXT.values:\n",
    "        note_tokenized = word_tokenize(note)\n",
    "        corpus_processed.append(note_tokenized)\n",
    "\n",
    "    return corpus_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:51:49.053827Z",
     "start_time": "2022-02-07T05:51:45.820858Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eea55e0751d448756b873af34f88fa24",
     "grade": false,
     "grade_id": "cell-98e3c75e6503a17f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "corpus_processed = preprocess_dataset(corpus_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:51:49.075679Z",
     "start_time": "2022-02-07T05:51:49.055575Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5205dfcdf9fcf0d5ee9d31b0a2cc366",
     "grade": false,
     "grade_id": "cell-b18d8af03ccfa839",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "assert len(corpus_processed) == 3633\n",
    "\n",
    "for article in corpus_processed:\n",
    "    assert '/' not in article, \"punctuation '/' is not removed!\"\n",
    "    assert '1' not in article, \"number '1' is not removed!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:51:49.209500Z",
     "start_time": "2022-02-07T05:51:49.077172Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a53995ec366b5126e2ac15061ecc76ef",
     "grade": true,
     "grade_id": "cell-b95b4537f3421f02",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c7bb4ca0d67caba4fa901676776250c2",
     "grade": false,
     "grade_id": "cell-26ec70e552d7447c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2 Train a word2vec model [20 points]\n",
    "\n",
    "Now that your data is pre-processed, your training dataset is ready. We will be using Word2Vec from gensim. You should:\n",
    "1. Set the word vector size to 100. \n",
    "2. Ignores all words with total frequency lower than (<) 20. \n",
    "3. use only 1 worker (workers=1) to ensure deterministic behavior\n",
    "4. set the seed to the provided value RANDOM_SEED\n",
    "Keep the other paramters as default. Train the model (Word2Vec) on the training dataset.\n",
    "\n",
    "REFERENCE: [tutorial](https://radimrehurek.com/gensim/models/word2vec.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:51:53.420159Z",
     "start_time": "2022-02-07T05:51:49.210908Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 23432098\n",
    "os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "\n",
    "# DO NOT modify these (or Coursera may timeout)!\n",
    "# Dimensionality of the word vectors\n",
    "VEC_SIZE = 100\n",
    "# Ignores all words with total frequency lower than this\n",
    "MIN_COUNT = 20\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\"\"\"\n",
    "TODO: Train the Word2Vec model (`w2v_model`).\n",
    "NOTE: Remember to set the `vec_size` and `min_count`.\n",
    "\"\"\"\n",
    "w2v_model = Word2Vec(sentences=corpus_processed, vector_size=VEC_SIZE, min_count=MIN_COUNT, workers=1)\n",
    "\n",
    "#raise NotImplementedError\n",
    "\n",
    "assert w2v_model.workers == 1, \"Please use only 1 worker for deterministic behavior.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:51:53.425635Z",
     "start_time": "2022-02-07T05:51:53.422113Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f67dba421b92f4881abb7b8965b8cf24",
     "grade": false,
     "grade_id": "cell-7f76d5e5bc961b32",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Size of vocab: %d\" % len(w2v_model.wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:51:53.433673Z",
     "start_time": "2022-02-07T05:51:53.431320Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71f9d79e8d524cca4047d79537ce2a85",
     "grade": false,
     "grade_id": "cell-b73537b2d7a4fab9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "assert isinstance(corpus_processed, list)\n",
    "assert isinstance(w2v_model, Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:51:53.437804Z",
     "start_time": "2022-02-07T05:51:53.435388Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b5beb4d9dd6a34f1faf6cc7701f4c90",
     "grade": true,
     "grade_id": "cell-675c09b559fd1a35",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87111c81fde81778c52fed58002abdb9",
     "grade": false,
     "grade_id": "cell-d522f551ab504e34",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.3 Evaluate the model [20 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d6a4bdc9df83ae1f3bea582666b8cf71",
     "grade": false,
     "grade_id": "cell-06afb6c19c18b838",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Find distinct word*: Given three words (e.g. 'heart', 'lung' and 'protein'), find the distinct word (e.g. 'protein')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:51:53.441875Z",
     "start_time": "2022-02-07T05:51:53.439350Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "#input\n",
    "# model: word2vec model\n",
    "# list_of_words: a list of words, e.g. ['heart', 'lung', 'protein']\n",
    "#output\n",
    "# distinct_word: the distinct word\n",
    "def find_distinct_word(model, list_of_words):\n",
    "    \n",
    "    \"\"\"\n",
    "    TODO: Find the distinct word from the list using the trained word2vec model.\n",
    "    HINT: Consider the *doesnt_match* method.\n",
    "    \"\"\"\n",
    "    return model.wv.doesnt_match(list_of_words)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:51:53.449930Z",
     "start_time": "2022-02-07T05:51:53.443379Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a3824e1484873121d5e6bdbae9d0000",
     "grade": false,
     "grade_id": "cell-70c9f6f90b1753cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "list_of_words = ['heart', 'lung', 'protein']\n",
    "assert type(find_distinct_word(w2v_model, list_of_words)) is str\n",
    "print(\"The distinct word among '%s' is: '%s'.\" % (', '.join(list_of_words), find_distinct_word(w2v_model, list_of_words)))\n",
    "\n",
    "list_of_words = ['carbohydrate', 'sugars', 'lung']\n",
    "assert type(find_distinct_word(w2v_model, list_of_words)) is str\n",
    "print(\"The distinct word among '%s' is: '%s'.\" % (', '.join(list_of_words), find_distinct_word(w2v_model, list_of_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:51:53.454441Z",
     "start_time": "2022-02-07T05:51:53.451459Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2f008c02857d9df7c266a3c9ef2e888",
     "grade": true,
     "grade_id": "cell-c3c73f089da4be5b",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cfaca95abf75da1a15e5fd64132f398f",
     "grade": false,
     "grade_id": "cell-d9197cf113a928f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Similar words**: Given a word (e.g. 'blood'), find the list of words similar to this word (e.g. one such word is 'pressure')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:51:53.461617Z",
     "start_time": "2022-02-07T05:51:53.457781Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "#input: model: word2vec model\n",
    "#       word: a single word, e.g. 'heart'\n",
    "#output: list_of_words: a list of words similar to the given word\n",
    "def similar_word(model, word):\n",
    "    \n",
    "    \"\"\"\n",
    "    TODO: Find the words similar to the given word.\n",
    "    HINT: Consider the *most_similar* method.\n",
    "    \"\"\"\n",
    "    \n",
    "    list_of_words = []\n",
    "\n",
    "    model_out = w2v_model.wv.most_similar(word)\n",
    "    list_of_words = list(zip(*model_out))[0]\n",
    "    \n",
    "    return list(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:51:53.470770Z",
     "start_time": "2022-02-07T05:51:53.463456Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e34d43a9628f5570e8ac59daa229a82d",
     "grade": false,
     "grade_id": "cell-b576a0ef65af7da9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "word = 'blood'\n",
    "assert type(similar_word(w2v_model, word)) is list\n",
    "print(\"The words similar to '%s' are: '%s'.\" % (word, ', '.join(similar_word(w2v_model, word))))\n",
    "\n",
    "word = 'protein'\n",
    "assert type(similar_word(w2v_model, word)) is list\n",
    "print(\"The words similar to '%s' are: '%s'.\" % (word, ', '.join(similar_word(w2v_model, word))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:51:53.476768Z",
     "start_time": "2022-02-07T05:51:53.472750Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "378e22fb59d6f111d5c5216494eba6ad",
     "grade": true,
     "grade_id": "cell-3060fb5d67bb9eb4",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0147802b2e693c0e15ae3c9040178836",
     "grade": false,
     "grade_id": "cell-943fce440bd3fb16",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2 t-SNE, UMAP [40 points]\n",
    "\n",
    "In this question, you will perform t-SNE and UMAP on the medical representations obtained from the previous sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:51:53.492556Z",
     "start_time": "2022-02-07T05:51:53.478912Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a12f92f1083bab878d3b46b7e65bd04",
     "grade": false,
     "grade_id": "cell-6ab000213ab012c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# load the word2vec model from Q2\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# words\n",
    "W = list(w2v_model.wv.key_to_index.keys())\n",
    "# embeddings\n",
    "X = np.array([w2v_model.wv[w] for w in W])\n",
    "\n",
    "# select only a subset of the words\n",
    "X_subset = X[:1000]\n",
    "W_subset = W[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:51:54.307083Z",
     "start_time": "2022-02-07T05:51:53.494654Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d85040632cd9b791086d314ca2d1b83a",
     "grade": false,
     "grade_id": "cell-f4c5333510bb0a62",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def plot(X, Y, W):\n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "    ax.plot(Y[:, 0], Y[:, 1], 'o')\n",
    "    ax.set_yticklabels([]) #Hide ticks\n",
    "    ax.set_xticklabels([]) #Hide ticks\n",
    "\n",
    "    for i, word in enumerate(W):\n",
    "        if random.uniform(0,1) > 0.9:\n",
    "            plt.annotate(word, xy=(Y[i, 0], Y[i, 1]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "81b2f5c1aca7fb3a905bbb01297122db",
     "grade": false,
     "grade_id": "cell-c7582cb8cb8ad50d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.1 t-SNE [20 points]\n",
    "\n",
    "Perform t-SNE on `X_subset` and plot the results. \n",
    "\n",
    "REFERENCE: [tutorial](https://www.datacamp.com/community/tutorials/introduction-t-sne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:51:57.660490Z",
     "start_time": "2022-02-07T05:51:54.308675Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# t-SNE\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "TODO: Perform t-SNE on `X_subset`.\n",
    "\"\"\"\n",
    "\n",
    "Y_subset_tsne = None\n",
    "tsne = TSNE(n_components=2)\n",
    "Y_subset_tsne = tsne.fit_transform(X_subset)\n",
    "tsne.kl_divergence_\n",
    "\n",
    "\n",
    "#raise NotImplementedError\n",
    "\n",
    "plot(X_subset, Y_subset_tsne, W_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:51:57.665082Z",
     "start_time": "2022-02-07T05:51:57.661693Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5684b2683f6b8976bcdf2fa659c65e90",
     "grade": false,
     "grade_id": "cell-1089364de1d0e97c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "from inspect import signature\n",
    "\n",
    "assert len(Y_subset_tsne)==1000, \"Y_subset_tsne has wrong dimensions\"\n",
    "sig = signature(plot)\n",
    "assert len(sig.parameters)==3, \"need to plot all dimensions of t-SNE!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:51:57.669928Z",
     "start_time": "2022-02-07T05:51:57.667417Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38e9d521d50f641fb368a14058f9d2eb",
     "grade": true,
     "grade_id": "cell-a10e0b6551a4e6de",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aad35193812ae21cc63f3efd51c64859",
     "grade": false,
     "grade_id": "cell-1f88a47aa8bd60e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.2 UMAP [20 points]\n",
    "\n",
    "Perform UMAP on `X_subset` and plot the results. \n",
    "\n",
    "REFERENCE: [tutorial](https://umap-learn.readthedocs.io/en/latest/basic_usage.html#digits-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:52:23.175073Z",
     "start_time": "2022-02-07T05:51:57.671276Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# UMAP\n",
    "\n",
    "import umap.umap_ as umap #package is umap-learn\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "TODO: Perform UMAP on `X_subset`.\n",
    "\"\"\"\n",
    "\n",
    "Y_subset_umap = None\n",
    "\n",
    "Y_subset_umap = umap.UMAP()\n",
    "Y_subset_umap = Y_subset_umap.fit_transform(X_subset)\n",
    "\n",
    "\n",
    "#raise NotImplementedError\n",
    "\n",
    "plot(X_subset, Y_subset_umap, W_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:52:23.186304Z",
     "start_time": "2022-02-07T05:52:23.176883Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "444c375ab1ac2b36ba2959a6fd633b59",
     "grade": false,
     "grade_id": "cell-6a73cd01e399bfab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "from inspect import signature\n",
    "\n",
    "assert len(Y_subset_umap)==1000, \"Y_subset_umap has wrong dimensions\"\n",
    "sig = signature(plot)\n",
    "assert len(sig.parameters)==3, \"need to plot all dimensions of UMAP!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T05:52:23.192488Z",
     "start_time": "2022-02-07T05:52:23.188429Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "128070d2c052a0073c6bb4b03b1ec22b",
     "grade": true,
     "grade_id": "cell-e0b9149a175c8ac2",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f150f4f4d012389d480e57a5942b410",
     "grade": false,
     "grade_id": "cell-ea4894d3630e1b9b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Check if the embeddings make sense. Due to the hardware and runtime limitation, we cannot reach the state-of-the-art performance. But you will have chance to work with more advanced models in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "illinois_payload": {
   "b64z": "",
   "nb_path": "release/HW2_Embedding/HW2_Embedding.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (Threads: 2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "292.390625px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "524px",
    "left": "1423px",
    "right": "20px",
    "top": "120px",
    "width": "348px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
